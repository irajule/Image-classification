# Import necessary libraries
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import torchvision
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
from skimage import io
import pandas as pd
import os
from torchvision.ops import nms
import optuna
from sklearn.model_selection import train_test_split
from torch.cuda.amp import GradScaler, autocast

# Custom dataset class
class Apples(Dataset):
    def __init__(self, csv_file, root_dir, transform=None):
        self.annot = pd.read_csv(csv_file)
        self.root_dir = root_dir
        self.transform = transform

    def __len__(self):
        return len(self.annot)

    def __getitem__(self, index):
        img_path = os.path.join(self.root_dir, self.annot.iloc[index, 0])
        image = io.imread(img_path)
        y_label = torch.tensor(int(self.annot.iloc[index, 1]))
        if self.transform:
            image = self.transform(image)
        return (image, y_label)

# Define the CNN model
class Network(nn.Module):
    def __init__(self, dropout_rate=0.5):
        super(Network, self).__init__()
        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)
        self.batch_norm1 = nn.BatchNorm2d(32)
        self.batch_norm2 = nn.BatchNorm2d(64)
        self.batch_norm3 = nn.BatchNorm2d(128)
        self.batch_norm4 = nn.BatchNorm2d(256)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
        self.dropout = nn.Dropout(dropout_rate)
        self.fc1 = nn.Linear(256*2*2, 512)
        self.fc2 = nn.Linear(512, 128)
        self.fc3 = nn.Linear(128, 7)

    def forward(self, x):
        x = self.pool(F.relu(self.batch_norm1(self.conv1(x))))
        x = self.pool(F.relu(self.batch_norm2(self.conv2(x))))
        x = self.pool(F.relu(self.batch_norm3(self.conv3(x))))
        x = self.pool(F.relu(self.batch_norm4(self.conv4(x))))
        x = x.view(-1, 256*2*2)
        x = F.relu(self.fc1(x))
        x = self.dropout(x)
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x

# Data augmentation and normalization
transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),
    transforms.Resize((32, 32)),
    transforms.ToTensor(),
])

# Load the dataset
dataset = Apples(csv_file='train.csv', root_dir='train_images', transform=transform)
train_size = int(0.8 * len(dataset))
val_size = len(dataset) - train_size
train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])
train_loader = DataLoader(train_dataset, batch_size=100, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=100, shuffle=False)

# Function to train the model
def train_model(model, optimizer, criterion, num_epochs, patience, scheduler=None):
    best_loss = float('inf')
    epochs_no_improve = 0
    early_stop = False
    train_losses, val_losses = [], []
    scaler = GradScaler()  # Mixed precision training

    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            with autocast():  # Mixed precision training
                outputs = model(images)
                loss = criterion(outputs, labels)
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()
            running_loss += loss.item()

        if scheduler:
            scheduler.step()

        val_loss = 0.0
        model.eval()
        with torch.no_grad():
            for images, labels in val_loader:
                images, labels = images.to(device), labels.to(device)
                outputs = model(images)
                loss = criterion(outputs, labels)
                val_loss += loss.item()

        train_losses.append(running_loss / len(train_loader))
        val_losses.append(val_loss / len(val_loader))

        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {running_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(val_loader):.4f}')

        if val_loss < best_loss:
            best_loss = val_loss
            epochs_no_improve = 0
            torch.save(model.state_dict(), 'best_model.pth')
        else:
            epochs_no_improve += 1
            if epochs_no_improve == patience:
                print("Early stopping")
                early_stop = True
                break

    return train_losses, val_losses

# Bayesian optimization function
def objective(trial):
    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)
    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)
    weight_decay = trial.suggest_float('weight_decay', 1e-5, 1e-2, log=True)

    model = Network(dropout_rate=dropout_rate).to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)
    criterion = nn.CrossEntropyLoss()
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)

    train_model(model, optimizer, criterion, num_epochs=20, patience=5, scheduler=scheduler)

    model.load_state_dict(torch.load('best_model.pth'))
    model.eval()

    val_loss = 0.0
    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            val_loss += loss.item()

    return val_loss / len(val_loader)

# Run Bayesian optimization
study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=20)

# Load the best model and evaluate on the test set
best_trial = study.best_trial
print(f'Best trial: Value: {best_trial.value}, Params: {best_trial.params}')

best_model = Network(dropout_rate=best_trial.params['dropout_rate']).to(device)
best_model.load_state_dict(torch.load('best_model.pth'))

# Prepare test data
test_transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize((32, 32)),
    transforms.ToTensor(),
])
test_dataset = Apples(csv_file='test.csv', root_dir='test_images', transform=test_transform)
test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)

# Test the model
best_model.eval()
total_correct = 0
with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = best_model(images)
        _, preds = torch.max(outputs, 1)
        total_correct += (preds == labels).sum().item()

accuracy = total_correct / len(test_dataset)
print(f'Accuracy: {accuracy * 100:.2f}%')
